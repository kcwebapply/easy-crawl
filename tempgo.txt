package crawl

import (
	"fmt"
	"net/http"
	"net/url"

	"github.com/PuerkitoBio/goquery"
)

type EasyCrawler struct {
	Depth       int
	ReadUrlList []string

	depth_counter int
}

func (crawler *EasyCrawler) Crawl(depth int, u string) {

	contentChannel := make(chan bool)
	depthCountChanel := make(chan bool)
	crawler.crawl(u, contentChannel, depthCountChanel)
}

func (crawler *EasyCrawler) crawl(u string, c chan bool, d chan bool) {
	var content, _ = crawler.getContentFromUrl(u)
	crawler.saveHost(u)
	//fmt.Println("content:", content.Url)

	//fmt.Println(content.Urls)
	for _, url := range content.Urls {
		go crawler(url, c)
	}
}



/*func (crawler *EasyCrawler) crawl(u string, c *Channel) {
	var content, _ = crawler.getContentFromUrl(u)
	crawler.saveHost(u)
	//fmt.Println("content:", content.Url)

	//fmt.Println(content.Urls)
	for _, url := range content.Urls {
		go crawler(url)
	}
}*/

func (crawler *EasyCrawler) getContentFromUrl(u string) (*Content, error) {
	var urls = []string{}

	baseUrl, urlParseError := url.Parse(u)
	if urlParseError != nil {
		fmt.Println("url parse error:", urlParseError)
		return nil, urlParseError
	}

	resp, httpGetError := http.Get(baseUrl.String())
	if httpGetError != nil {
		fmt.Println("http error:", httpGetError)
		return nil, httpGetError
	}

	doc, err := goquery.NewDocumentFromReader(resp.Body)
	html, htmlGetError := doc.Html()
	if htmlGetError != nil {
		fmt.Println("html extract error:", htmlGetError)
		return nil, htmlGetError
	}

	// parse a tag and href
	doc.Find("a").Each(func(_ int, s *goquery.Selection) {
		href, exists := s.Attr("href")
		if exists {
			reqUrl, err := url.Parse(href)
			for _, v := range urls {
				if reqUrl.String() == v {
					return
				}
			}
			if err == nil {
				urls = append(urls, reqUrl.String())
			}
		}
	})

	return &Content{Url: baseUrl.String(), Urls: urls, Body: html}, err
}

func (crawler *EasyCrawler) saveHost(u string) {
	for _, v := range crawler.ReadUrlList {
		if u == v {
			return
		}
	}
	crawler.ReadUrlList = append(crawler.ReadUrlList, u)
}

func (crawler *EasyCrawler) SetCallBack() {
	fmt.Println("set CallBack!")
}
